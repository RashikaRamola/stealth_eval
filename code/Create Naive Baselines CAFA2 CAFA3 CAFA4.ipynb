{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c4a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import csv\n",
    "import io\n",
    "import argparse\n",
    "\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/rashika/CAFA4/InformationAccretion/\")\n",
    "sys.path.append(\"/home/rashika/CAFA4/CAFA-evaluator/src/cafaeval/\")\n",
    "from parser import *\n",
    "from ia import *\n",
    "from make_benchmarks import *\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f683ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Read a the processed annotation file, map the primary ID to a mapping file, and keep the rows that can be mapped.\n",
    "\n",
    "    Parameters:\n",
    "    - processed_file_path: Path to the file containing processed GOA annotations\n",
    "    - mapping_file: Path to the mapping file \n",
    "    - out_path: Path to the output file.\n",
    "    \"\"\"\n",
    "def goa_to_CAFA4ID(processed_file_path, mapping_file, out_path):\n",
    "    ann = pd.read_csv(processed_file_path, sep = '\\t', header = 0)\n",
    "    mapping = pd.read_csv(mapping_file, sep = '\\t', header = 0)\n",
    "\n",
    "    # Inner join the processed annotations and the mapping based on DB Object ID\n",
    "    mapped =  pd.merge(ann, mapping, on='DB Object ID', how='inner')\n",
    "    \n",
    "    \n",
    "    # Keep the required columns\n",
    "    mapped = mapped[[\"CAFA_ID\", \"GO ID\", \"Aspect\"]]\n",
    "    \n",
    "    # Write the mapped file to the out_path\n",
    "    mapped.to_csv(out_path, sep = \"\\t\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d1a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocess_cmd(gaf_path, out_path):\n",
    "    cmd = [\n",
    "    \"python3\",                 # Command to execute Python 3\n",
    "    \"preprocess_gaf.py\",       # Script to run\n",
    "    gaf_path,  # Path to input file\n",
    "    \"--highTP\",\n",
    "    \"--out_path\", out_path,        # Output path parameter\n",
    "    #\"--evidence_codes\", \"EXP\", \"IDA\",   # Evidence codes parameter\n",
    "    #\"--extract_col_list\", \"DB Object ID\", \"Qualifier\"  # Extract column list parameter\n",
    "]\n",
    "    return cmd\n",
    "\n",
    "def run_process(command, log_file):\n",
    "    print(\" \".join(command))\n",
    "    #with open(log_file, \"w\") as f:\n",
    "    #    print(\" \".join(command))\n",
    "        #result = subprocess.run(\" \".join(command), shell=True, stdout=f, stderr=subprocess.STDOUT)\n",
    "        #if result.returncode != 0:\n",
    "        #    print(f\"Error running command: {' '.join(command)}. Check {log_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3879da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Define commands and log file names\n",
    "    work_dir = \"/data/rashika/CAFA4/\"\n",
    "    \n",
    "    t0_CAFA2_2014 = work_dir + 'uniprot/goa_2014-01-21/gene_association.goa_uniprot.127.gz'\n",
    "    t0_CAFA3_2017 = work_dir + 'uniprot/goa_2017-01-17/goa_uniprot_all.gaf.162.gz'\n",
    "    \n",
    "    t0_CAFA2_2014_processed = work_dir + 'extracted_goa/goa_2014-01-21/preprocessed.csv'\n",
    "    t0_CAFA3_2017_processed = work_dir + 'extracted_goa/goa_2017-01-17/preprocessed.csv'\n",
    "    \n",
    "    t0_CAFA2_2014_log = work_dir + 'log/goa_2014-01-21.txt'\n",
    "    t0_CAFA3_2017_log = work_dir + 'log/goa_2017-01-17.txt'\n",
    "    \n",
    "    cmd_preprocess_t0_CAFA2_2014 = get_preprocess_cmd(t0_CAFA2_2014, t0_CAFA2_2014_processed)\n",
    "    cmd_preprocess_t0_CAFA3_2017 = get_preprocess_cmd(t0_CAFA3_2017, t0_CAFA3_2017_processed)\n",
    "    \n",
    "    #run_process(cmd_preprocess_t0_CAFA2_2014, t0_CAFA2_2014_log)\n",
    "    #run_process(cmd_preprocess_t0_CAFA3_2017, t0_CAFA3_2017_log)\n",
    "    \n",
    "    mapping_file_CAFA2 = \"/data/common/CAFA4/h2h/AC2CAFA2ID.map\"\n",
    "    mapping_file_CAFA3 = \"/data/common/CAFA4/h2h/AC2CAFA3ID.map\"\n",
    "    \n",
    "    mapped_path_CAFA2 = work_dir + \"mapped/CAFA2_IDs/2014-01-21/t0_CAFA2_2014.csv\"\n",
    "    mapped_path_CAFA3 = work_dir + \"mapped/CAFA3_IDs/2017-01-17/t0_CAFA3_2017.csv\"\n",
    "    \n",
    "    \n",
    "    # Map to CAFA4 IDs \n",
    "    #goa_to_CAFA4ID(t0_CAFA2_2014_processed, mapping_file_CAFA2, mapped_path_CAFA2)\n",
    "    #goa_to_CAFA4ID(t0_CAFA3_2017_processed, mapping_file_CAFA3, mapped_path_CAFA3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca9a886",
   "metadata": {},
   "source": [
    "## Write new code to generate Naive baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b71f5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_naive_pred(gt_file, obo_file, out_file_path):\n",
    "    # Parse the OBO file and creates a different graphs for each namespace\n",
    "    ontologies = obo_parser(obo_file, (\"is_a\", \"part_of\"))\n",
    "\n",
    "    # Parse ground truth file\n",
    "    gt = gt_parser(gt_file, ontologies)\n",
    "    \n",
    "    ont_preds = []\n",
    "    for aspect in ontologies.keys():\n",
    "        IDs = gt[aspect].ids\n",
    "        naive_score = sum(gt[aspect].matrix)/len(gt[aspect].matrix[0]) # Frequency of each GO term/Number of GO terms\n",
    "\n",
    "        pred = [] # Initialise prediction dict\n",
    "\n",
    "        for k in ontologies[aspect].terms_dict.keys():\n",
    "            pred.append([k, naive_score[ontologies[aspect].terms_dict[k]['index']]])\n",
    "        pred = pd.DataFrame(pred, columns = ['GO_term', 'score'])\n",
    "        preds = [pred.assign(Protein = protein) for protein in IDs]\n",
    "        ont_preds.append(pd.concat(preds, ignore_index=True))\n",
    "    Final_pred = pd.concat(ont_preds, ignore_index=True)\n",
    "    Final_pred = Final_pred[[\"Protein\", \"GO_term\", 'score']]\n",
    "    Final_pred.to_csv(os.path.join(out_file_path, 'naive_'+ gt_file.split(\"/\")[-1]), sep = \"\\t\", header = None, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6b0ec64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cafa_file_map = {'cafa4': {'gt_file': '/data/rashika/CAFA4/mapped/2019-12-17/t0_2019.csv', 'obo_file': \"/data/rashika/CAFA4/obo/go_2019_10_07/go-basic.obo\", 'out_file_path': \"/data/rashika/CAFA4/baselines/naive/cafa4/\"}, \n",
    "            'cafa3': {'gt_file': \"/data/rashika/CAFA4/mapped/CAFA3_IDs/2017-01-17/t0_CAFA3_2017.csv\", 'obo_file': \"/data/rashika/CAFA4/obo/go_2016-06-01/go-basic.obo\", 'out_file_path': \"/data/rashika/CAFA4/baselines/naive/cafa3/\"}, \n",
    "            'cafa2': {'gt_file': \"/data/rashika/CAFA4/mapped/CAFA2_IDs/2014-01-21/t0_CAFA2_2014.csv\", 'obo_file': \"/data/rashika/CAFA4/obo/go_2013-09-01/go-basic.obo\", 'out_file_path': \"/data/rashika/CAFA4/baselines/naive/cafa2/\"}\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3056e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gt_file': '/data/rashika/CAFA4/mapped/2019-12-17/t0_2019.csv', 'obo_file': '/data/rashika/CAFA4/obo/go_2019_10_07/go-basic.obo', 'out_file_path': '/data/rashika/CAFA4/baselines/naive/cafa4/'}\n",
      "done cafa4\n",
      "{'gt_file': '/data/rashika/CAFA4/mapped/CAFA3_IDs/2017-01-17/t0_CAFA3_2017.csv', 'obo_file': '/data/rashika/CAFA4/obo/go_2016-06-01/go-basic.obo', 'out_file_path': '/data/rashika/CAFA4/baselines/naive/cafa3/'}\n",
      "done cafa3\n",
      "{'gt_file': '/data/rashika/CAFA4/mapped/CAFA2_IDs/2014-01-21/t0_CAFA2_2014.csv', 'obo_file': '/data/rashika/CAFA4/obo/go_2013-09-01/go-basic.obo', 'out_file_path': '/data/rashika/CAFA4/baselines/naive/cafa2/'}\n",
      "done cafa2\n"
     ]
    }
   ],
   "source": [
    "for cafa, files in cafa_file_map.items():\n",
    "    print(files)\n",
    "    get_naive_pred(files['gt_file'], files['obo_file'], files['out_file_path'])\n",
    "    print('done', cafa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb26da17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
